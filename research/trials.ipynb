{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3e9435d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\Soumya Sengupta\\Desktop\\Medibot\\FirstAid.AI\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Full path to your project (adjust the username if needed)\n",
    "project_path = os.path.expanduser(\"~/Desktop/Medibot/FirstAid.AI\")\n",
    "\n",
    "# Change working directory\n",
    "os.chdir(project_path)\n",
    "\n",
    "# Confirm it's set correctly\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad18fa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Soumya Sengupta\\\\Desktop\\\\Medibot\\\\FirstAid.AI'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b470036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dc4f77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents=loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "779c404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf_file(data='Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "29e46826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0917963d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5860\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4a8ef99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceHubEmbeddings\n",
    "\n",
    "def download_embeddings_hfhub():\n",
    "    embeddings = HuggingFaceHubEmbeddings(\n",
    "        repo_id=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        huggingfacehub_api_token=os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embeddings=download_embeddings_hfhub()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9bdc46e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "572ef32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4de77e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f793b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "index_name = \"medichat\"\n",
    "\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384, \n",
    "    metric=\"cosine\", \n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\", \n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "46f7c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8f1c6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "17134bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "93cf2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama3-70b-8192\",  # or mistral-7b, llama2-70b\n",
    "    api_key=groq_api_key,\n",
    "    temperature=0.4,\n",
    "    max_tokens=500,\n",
    ")\n",
    "\n",
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use ten sentences maximum and keep the \"\n",
    "    \"answer concise.\\n\\n{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1a779272",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2945249a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Soumya Sengupta\\anaconda3\\envs\\medic\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronic kidney disease (CKD) is a gradual loss of kidney function over time, leading to the kidneys being unable to filter waste and excess fluids from the blood effectively.\n",
      "\n",
      "The stages of CKD are based on the level of kidney function, which is measured by the glomerular filtration rate (GFR). The stages are:\n",
      "\n",
      "1. Stage 1: Kidney damage with normal GFR (â‰¥90 mL/min)\n",
      "2. Stage 2: Mild reduction in GFR (60-89 mL/min)\n",
      "3. Stage 3: Moderate reduction in GFR (30-59 mL/min)\n",
      "4. Stage 4: Severe reduction in GFR (15-29 mL/min)\n",
      "5. Stage 5: End-stage renal disease (ESRD) with GFR <15 mL/min\n",
      "\n",
      "Lab tests to diagnose and monitor CKD include:\n",
      "\n",
      "1. Blood tests:\n",
      "\t* Creatinine: measures kidney function\n",
      "\t* Blood urea nitrogen (BUN): measures waste products in the blood\n",
      "\t* Electrolyte panel: measures sodium, potassium, and other electrolytes\n",
      "2. Urine tests:\n",
      "\t* Urinalysis: examines the physical and chemical properties of urine\n",
      "\t* Proteinuria: measures protein levels in urine\n",
      "\t* Creatinine clearance: measures kidney function\n",
      "3. Other tests:\n",
      "\t* Glomerular filtration rate (GFR) calculation: estimates kidney function\n",
      "\t* Kidney ultrasound: examines kidney structure and function\n",
      "\t* Kidney biopsy: examines kidney tissue for damage or disease\n",
      "\n",
      "Regular monitoring of these lab tests helps healthcare providers track the progression of CKD and adjust treatment plans accordingly.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is chronic kidney disease and what are its stages? What lab tests should be done?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccdf2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
